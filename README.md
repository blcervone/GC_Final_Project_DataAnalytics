# Real-Time Data Pipeline - Kafka, Docker, Spark, ETL, SQL, EDA and Power BI Dashboard

This project involved the development of a robust data pipeline to stream and analyze big data from the UK National Rail Database. The pipeline utilized a combination of cutting-edge technologies including Kafka Pipelines, Docker, Spark, PostgreSQL, Python, Pandas, Seaborn, and Power BI. The data streaming process began with Kafka Pipelines, which efficiently handled the ingestion of large volumes of real-time data from the UK National Rail Database. Docker was employed to containerize the various components of the pipeline, ensuring consistency and scalability across different environments. Spark was used for its powerful data processing capabilities, allowing for the transformation and aggregation of raw data. The processed data was then stored in a PostgreSQL database, providing a reliable and scalable storage solution. Python, along with Pandas and Seaborn, was utilized for exploratory data analysis (EDA). This involved accessing the data from the PostgreSQL database, cleaning and processing it, and performing various analyses to uncover insights and trends. Finally, the cleaned and processed data was loaded into Power BI, where an interactive data reporting dashboard was created. This dashboard provided a comprehensive view of the data, enabling stakeholders to make informed decisions based on real-time insights. The successful implementation of this project demonstrated the power and efficiency of modern data engineering and analytics tools. By leveraging these technologies, the project not only provided valuable insights into the UK National Rail data but also showcased the potential for scalable and real-time data processing solutions. This project serves as a testament to the capabilities of Python-based data pipelines in transforming raw data into actionable intelligence.
